{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9972e09a-9660-40d6-a049-65912c2ce915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinay/miniforge3/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.special import softmax\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import degree, dropout_adj\n",
    "from torch_geometric.nn import RGCNConv, GCNConv\n",
    "\n",
    "from helper.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a064db-b27e-449f-94a4-94a88236193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = Path('data/movie-lens/ml-latest-small')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SEED = 42\n",
    "EPOCHS=2\n",
    "BATCH_SIZE=512\n",
    "LR=1e-3\n",
    "LR_DECAY_STEP = 20\n",
    "LR_DECAY_VALUE = 10\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "    torch.cuda.synchronize()\n",
    "    device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970a1ec8-e57f-4836-a61e-03ddb3ccf056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(BASE_PATH/'movies.csv')\n",
    "df_links = pd.read_csv(BASE_PATH/'links.csv')\n",
    "df_tags = pd.read_csv(BASE_PATH/'tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff2032d-e06f-4439-bf25-ab058d930d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2    Jumanji (1995)                   Adventure|Children|Fantasy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0aa4051-4ea9-4208-bbdf-2da1fb9d989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0       2    60756            funny  1445714994\n",
       "1       2    60756  Highly quotable  1445714996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a836d5-e532-4063-9ee5-33bd61e236b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2    Jumanji (1995)                   Adventure|Children|Fantasy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419ba49d-a76f-4dda-8186-871fbee56a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myround(x, base=0.5):\n",
    "    return base * round(x/base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1223a8df-9168-4df9-b665-93b2c959bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_range(x, t_min, t_max):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    y = ((x - x_min)/(x_max - x_min)) * (t_max - t_min) + t_min\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8e81514-770b-4582-81bb-fa866b5410d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ratings(df_ratings):\n",
    "    user_mean_ratings = df_ratings.groupby('userId').mean().drop('movieId', axis=1).reset_index()\n",
    "    temp = pd.merge(df_ratings, user_mean_ratings, on='userId')\n",
    "    z = temp['rating_x'] - temp['rating_y']\n",
    "    temp['rating'] = myround(to_range(z, 0, 5))\n",
    "    # temp['rating'] += temp['rating'].min()\n",
    "    return temp.drop(labels=['rating_x', 'rating_y'], axis=1)\n",
    "\n",
    "# df_ratings = pd.read_csv(BASE_PATH/'ratings.csv').drop(labels='timestamp', axis=1)\n",
    "# df_ratings = transform_ratings(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7753eda7-4e4c-4d66-811e-a0d9a93df24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09c20c3-2259-4483-af1a-b1a492aca4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features[0, 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b33abc9-e0a4-4de9-bb93-9885e3b29f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3e577-22a5-43c5-a2b5-ba2a6d131420",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21cb8008-2b1b-4e9f-a0b6-f90a54338be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data):\n",
    "    uniq = list(set(data))\n",
    "    id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
    "    data = np.array([id_dict[x] for x in data])\n",
    "    n = len(uniq)\n",
    "\n",
    "    return data, id_dict, n\n",
    "\n",
    "def shuffle_df(df):\n",
    "    rand_idx = np.random.randint(0, df.shape[0], df.shape[0])\n",
    "    df = df.iloc[rand_idx, :].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_nodes(df_ratings):\n",
    "    df_ratings = shuffle_df(df_ratings)\n",
    "    rated_users = df_ratings.values[:, 0]\n",
    "    rated_items = df_ratings.values[:, 1]\n",
    "    ratings = df_ratings.values[:, 2]\n",
    "    \n",
    "    rated_users, rated_users_dict, num_users = map_data(rated_users)\n",
    "    rated_items, rated_items_dict, num_items = map_data(rated_items)\n",
    "    \n",
    "    return rated_users, rated_users_dict, num_users, rated_items, rated_items_dict, num_items, ratings\n",
    "\n",
    "def get_user_features(df_ratings, df_items, genres, genres_map, rated_users_dict, n, sparse=False):\n",
    "    n_users = len(df_ratings.userId.unique())\n",
    "    f_len = len(genres_map)\n",
    "    x = pd.merge(df_ratings, df_items).drop(labels=['title', 'movieId', 'rating', 'feature'], axis=1)\n",
    "    x = x.groupby('userId')[genres].mean()\n",
    "    y = x.apply(lambda x: pd.Series((x.nlargest(n))), axis=1).notna().reset_index()\n",
    "    \n",
    "    user_features = np.zeros((n_users, f_len))\n",
    "    for i in range(y.shape[0]):\n",
    "        temp = [0] * f_len\n",
    "        for col in y.columns:\n",
    "            if y.loc[i, col] == True:\n",
    "                if col in genres_map:\n",
    "                    user_features[rated_users_dict[y.loc[i, 'userId']], genres_map[col]] = 1\n",
    "        \n",
    "    if sparse:\n",
    "        user_features = sp.csr_matrix(item_features)\n",
    "    \n",
    "    return user_features\n",
    "\n",
    "def get_item_features(df_items, idx_map, sparse=False):\n",
    "    n_items = df_items.shape[0]\n",
    "    f_len = len(list(df_items.loc[0, 'feature']))\n",
    "    item_features = np.zeros((n_items, f_len), dtype=np.float32)\n",
    "    \n",
    "    for movie_id, feature_vec in df_items[['movieId', 'feature']].values.tolist():\n",
    "        if movie_id in idx_map:\n",
    "            item_features[idx_map[movie_id], :] = list(feature_vec)\n",
    "            \n",
    "    if sparse:\n",
    "        item_features = sp.csr_matrix(item_features)\n",
    "            \n",
    "    return item_features\n",
    "\n",
    "def process_movies(df_movies):\n",
    "    genres = set()\n",
    "    lists = df_movies.genres.values\n",
    "    mp = {}\n",
    "    \n",
    "    def encode(movie_genres):\n",
    "        res = []\n",
    "        for idx, genre in enumerate(genres):\n",
    "            if genre in movie_genres:\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "            mp[genre] = idx\n",
    "        return res + [''.join([str(i) for i in res])]\n",
    "    \n",
    "    for idx, lis in enumerate(lists):\n",
    "        for genre in lis.split('|'):\n",
    "            genres.add(genre)\n",
    "            \n",
    "    genres = sorted(genres)    \n",
    "    df_movies[genres + ['feature']] = df_movies.apply(lambda x: encode(x.genres), 1).values.tolist()\n",
    "        \n",
    "    return df_movies.drop(labels='genres', axis=1), genres, mp\n",
    "\n",
    "def split(data, rating_dict, ratio=0.8):\n",
    "    rated_users, rated_items, ratings = data\n",
    "    n = rated_items.shape[0]\n",
    "    n_train = int(n * ratio)\n",
    "    stacked = np.vstack([rated_users, rated_items]).T\n",
    "    train_pairs_idx = stacked[:n_train]\n",
    "    test_pairs_idx = stacked[n_train:]\n",
    "    \n",
    "    user_train_idx, item_train_idx = train_pairs_idx.transpose()\n",
    "    user_test_idx, item_test_idx = test_pairs_idx.transpose()\n",
    "    \n",
    "    labels = np.array([rating_dict[r] for r in ratings], dtype=np.int32)\n",
    "    train_labels = labels[:n_train]\n",
    "    test_labels = labels[n_train:]\n",
    "    \n",
    "    return user_train_idx, item_train_idx, user_test_idx, item_test_idx, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e463823-3d06-4145-b1f4-730025721694",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, adj_mat, links, labels, h, sample_ratio, max_nodes_per_hop, \n",
    "                 u_features, v_features, class_values, max_num=None, root='data/movie-lens/ml-latest-small/'):\n",
    "        super(MovieLensDataset, self).__init__(root)\n",
    "        self.Arow = SparseRowIndexer(adj_mat)\n",
    "        self.Acol = SparseColIndexer(adj_mat.tocsc())\n",
    "        self.links = links\n",
    "        self.labels = labels\n",
    "        self.h = h\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.max_nodes_per_hop = max_nodes_per_hop\n",
    "        self.u_features = u_features\n",
    "        self.v_features = v_features\n",
    "        self.class_values = class_values\n",
    "        if max_num is not None:\n",
    "            np.random.seed(123)\n",
    "            num_links = len(links[0])\n",
    "            perm = np.random.permutation(num_links)\n",
    "            perm = perm[:max_num]\n",
    "            self.links = (links[0][perm], links[1][perm])\n",
    "            self.labels = labels[perm]\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.links[0])\n",
    "\n",
    "    def get(self, idx):\n",
    "        i, j = self.links[0][idx], self.links[1][idx]\n",
    "        g_label = self.labels[idx]\n",
    "        tmp = subgraph_extraction_labeling(\n",
    "            (i, j), self.Arow, self.Acol, self.h, self.sample_ratio, self.max_nodes_per_hop, \n",
    "            self.u_features, self.v_features, self.class_values, g_label\n",
    "        )\n",
    "        return construct_pyg_graph(*tmp)\n",
    "    \n",
    "class IGMC(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IGMC, self).__init__()\n",
    "        self.rel_graph_convs = torch.nn.ModuleList()\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=4, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.linear_layer1 = Linear(256, 128)\n",
    "        self.linear_layer2 = Linear(128, 1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.linear_layer1.reset_parameters()\n",
    "        self.linear_layer2.reset_parameters()\n",
    "        for i in self.rel_graph_convs:\n",
    "            i.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        num_nodes = len(data.x)\n",
    "        edge_index_dr, edge_type_dr = dropout_adj(data.edge_index, data.edge_type, p=0.2, num_nodes=num_nodes, training=self.training)\n",
    "\n",
    "        out = data.x\n",
    "        h = []\n",
    "        for conv in self.rel_graph_convs:\n",
    "            out = conv(out, edge_index_dr, edge_type_dr)\n",
    "            out = torch.tanh(out)\n",
    "            h.append(out)\n",
    "        h = torch.cat(h, 1)\n",
    "        h = [h[data.x[:, 0] == True], h[data.x[:, 1] == True]]\n",
    "        g = torch.cat(h, 1)\n",
    "        out = self.linear_layer1(g)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.linear_layer2(out)\n",
    "        out = out[:,0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "751a3c8a-82aa-4bc9-b8b9-d7ec5fe49043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    # a base GNN class, GCN message passing + sum_pooling\n",
    "    def __init__(self, dataset, gconv=GCNConv, latent_dim=[32, 32, 32, 1], \n",
    "                 regression=False, adj_dropout=0.2, force_undirected=False):\n",
    "        super(GNN, self).__init__()\n",
    "        self.regression = regression\n",
    "        self.adj_dropout = adj_dropout \n",
    "        self.force_undirected = force_undirected\n",
    "        # self.convs = torch.nn.ModuleList()\n",
    "        # self.convs.append(gconv(dataset.num_features, latent_dim[0]))\n",
    "        # for i in range(0, len(latent_dim)-1):\n",
    "        #     self.convs.append(gconv(latent_dim[i], latent_dim[i+1]))\n",
    "        self.lin1 = Linear(sum(latent_dim), 128)\n",
    "        if self.regression:\n",
    "            self.lin2 = Linear(128, 1)\n",
    "        else:\n",
    "            self.lin2 = Linear(128, dataset.num_classes)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if self.adj_dropout > 0:\n",
    "            edge_index, edge_type = dropout_adj(\n",
    "                edge_index, edge_type, p=self.adj_dropout, \n",
    "                force_undirected=self.force_undirected, num_nodes=len(x), \n",
    "                training=self.training\n",
    "            )\n",
    "        concat_states = []\n",
    "        for conv in self.convs:\n",
    "            x = torch.tanh(conv(x, edge_index))\n",
    "            concat_states.append(x)\n",
    "        concat_states = torch.cat(concat_states, 1)\n",
    "        x = global_add_pool(concat_states, batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        if self.regression:\n",
    "            return x[:, 0]\n",
    "        else:\n",
    "            return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "class IGMC(GNN):\n",
    "    # The GNN model of Inductive Graph-based Matrix Completion. \n",
    "    # Use RGCN convolution + center-nodes readout.\n",
    "    def __init__(\n",
    "        self, dataset, gconv=RGCNConv, latent_dim=[32, 32, 32, 32, 32], \n",
    "        num_relations=5, num_bases=2, regression=False, adj_dropout=0.2, \n",
    "        force_undirected=False, side_features=False, n_side_features=0, \n",
    "        multiply_by=1,\n",
    "    ):\n",
    "        super(IGMC, self).__init__(\n",
    "            dataset, RGCNConv, latent_dim, regression, adj_dropout, force_undirected\n",
    "        )\n",
    "        self.multiply_by = multiply_by\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(gconv(dataset.num_features, latent_dim[0], num_relations, num_bases))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases))\n",
    "        self.lin1 = Linear(2*sum(latent_dim), 128)\n",
    "        self.side_features = side_features\n",
    "        if side_features:\n",
    "            self.lin1 = Linear(2*sum(latent_dim)+n_side_features, 128)\n",
    "\n",
    "    def forward(self, data):\n",
    "        start = time.time()\n",
    "        x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n",
    "        if self.adj_dropout > 0:\n",
    "            edge_index, edge_type = dropout_adj(\n",
    "                edge_index, edge_type, p=self.adj_dropout, \n",
    "                force_undirected=self.force_undirected, num_nodes=len(x), \n",
    "                training=self.training\n",
    "            )\n",
    "        concat_states = []\n",
    "        for conv in self.convs:\n",
    "            x = torch.tanh(conv(x, edge_index, edge_type))\n",
    "            concat_states.append(x)\n",
    "        concat_states = torch.cat(concat_states, 1)\n",
    "\n",
    "        users = data.x[:, 0] == 1\n",
    "        items = data.x[:, 1] == 1\n",
    "        x = torch.cat([concat_states[users], concat_states[items]], 1)\n",
    "        if self.side_features:\n",
    "            x = torch.cat([x, data.u_feature, data.v_feature], 1)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        if self.regression:\n",
    "            return x[:, 0] * self.multiply_by\n",
    "        else:\n",
    "            return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a07a3217-35e4-4dd7-8f53-76aa827839b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items, genres, genres_mp  = process_movies(df_movies)\n",
    "\n",
    "df_ratings = pd.read_csv(BASE_PATH/'ratings.csv').drop(labels='timestamp', axis=1)\n",
    "# df_ratings = transform_ratings(df_ratings)\n",
    "\n",
    "rated_users, rated_users_dict, num_users, rated_items, rated_items_dict, num_items, ratings = get_nodes(df_ratings)\n",
    "item_features = get_item_features(df_items, rated_items_dict, sparse=False)\n",
    "user_features = get_user_features(df_ratings, df_items, genres, genres_mp, rated_users_dict, n=2, sparse=False)\n",
    "class_values = np.sort(np.unique(ratings))\n",
    "rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "samples = (rated_users, rated_items, ratings)\n",
    "user_train_idx, item_train_idx, user_test_idx, item_test_idx, train_labels, test_labels = split(samples, rating_dict)\n",
    "\n",
    "data = train_labels + 1.\n",
    "data = data.astype(np.float32)\n",
    "adj_mat = sp.csr_matrix(\n",
    "    (data, [user_train_idx, item_train_idx]), \n",
    "    shape=[num_users, num_items], \n",
    "    dtype=np.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f9d3581-bcd0-45a4-98d6-39cfbc2526f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = MovieLensDataset(\n",
    "    root='data/movie-lens/ml-latest-small/',\n",
    "    adj_mat=adj_mat,\n",
    "    links=(user_train_idx, item_train_idx),\n",
    "    labels=train_labels,\n",
    "    h=1,\n",
    "    sample_ratio=1,\n",
    "    max_nodes_per_hop=200,\n",
    "    # u_features=None,\n",
    "    # v_features=None,\n",
    "    u_features=user_features,\n",
    "    v_features=item_features,\n",
    "    class_values=class_values,\n",
    ")\n",
    "\n",
    "test_dataset = MovieLensDataset(\n",
    "    adj_mat=adj_mat,\n",
    "    links=(user_test_idx, item_test_idx),\n",
    "    labels=test_labels,\n",
    "    h=1,\n",
    "    sample_ratio=1,\n",
    "    max_nodes_per_hop=200,\n",
    "    # u_features=None,\n",
    "    # v_features=None,\n",
    "    u_features=user_features,\n",
    "    v_features=item_features,\n",
    "    class_values=class_values,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2e732f1-fcff-42a7-88ba-08972faa8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = IGMC()\n",
    "\n",
    "num_relations = len(class_values)\n",
    "n_features = user_features.shape[1] + item_features.shape[1]\n",
    "model = IGMC(\n",
    "    train_dataset, \n",
    "    num_relations=num_relations, \n",
    "    num_bases=4, \n",
    "    regression=True, \n",
    "    adj_dropout=True, \n",
    "    force_undirected=True, \n",
    "    side_features=False, \n",
    "    n_side_features=n_features, \n",
    "    multiply_by=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dfe4850-ef96-4f7f-a600-e984c5c0e711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.85 2.6 1.59 1.42 1.53 1.46 1.35 1.53 epoch 1 ; train loss 1.999062024448153\n",
      "1.53 1.36 1.46 1.31 1.4 1.33 1.52 1.46 epoch 2 ; train loss 1.4232135514886246\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.reset_parameters()\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=0)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss_all = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_batch = train_batch.to(device)\n",
    "        # print(train_batch.x.shape)\n",
    "        y_pred = model(train_batch)\n",
    "        y_true = train_batch.y\n",
    "        train_loss = F.mse_loss(y_pred, y_true)\n",
    "        if idx % 20 == 0:\n",
    "            print(round(train_loss.item(), 2), end=' ')\n",
    "        train_loss.backward()\n",
    "        train_loss_all += BATCH_SIZE * float(train_loss)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    train_loss_all = train_loss_all / len(train_loader.dataset)\n",
    "    \n",
    "    print('epoch', epoch,'; train loss', train_loss_all)\n",
    "\n",
    "    if epoch % LR_DECAY_STEP == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] / LR_DECAY_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10dc2113-1171-4c4d-907d-0867f7024445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE loss 6.310193205201309\n",
      "test RMSE loss 2.5120097940098303\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "for test_batch in test_loader:\n",
    "    test_batch = test_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(test_batch)\n",
    "    y_true = test_batch.y\n",
    "    test_loss += F.mse_loss(y_pred, y_true, reduction='sum')\n",
    "    # torch.cuda.empty_cache()\n",
    "mse_loss = float(test_loss) / len(test_loader.dataset)\n",
    "\n",
    "print('test MSE loss', mse_loss)\n",
    "print('test RMSE loss', math.sqrt(mse_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966584d7-6ced-4098-8866-d4e2cd5dd08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
